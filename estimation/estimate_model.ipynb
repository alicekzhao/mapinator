{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook executes the complete estimation procedure required by The Mapinator Classification (Peters and Yu, 2023, work in progress), starting from placements data and ending with model estimates. Various components of this notebook can be altered to create different estimations under different constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires a multithreaded kernel; see https://julialang.github.io/IJulia.jl/stable/manual/installation/#Installing-additional-Julia-kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for converting API data for use with estimation is adapted from [a notebook](https://github.com/jbrightuniverse/mapinator/blob/master/estimation/2023_summer_projects/api_to_mapinator_julia.ipynb) written by Silas Kwok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by retrieving placements data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SBM API Data Filter (Julia Version)\n",
    "Adapted from James Yuming Yu (5 June 2023)\n",
    "\n",
    "Silas Kwok, 31 July 2023\n",
    "\n",
    "Adapted and modified for use with full estimation by James Yu, 17 September 2023\n",
    "\"\"\"\n",
    "\n",
    "using HTTP, JSON\n",
    "DEBUG_LEVEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function matches(keywords, phrase)\n",
    "    # checks if any of the keywords are in the phrase\n",
    "    for keyword in keywords\n",
    "        if occursin(keyword, phrase)\n",
    "            return true\n",
    "        end\n",
    "    end\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1a\n",
    "Retrieve the placement outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: request times out after 120 seconds. If the data takes longer than 120s to download, adjust the timeout.\n",
    "placements = nothing\n",
    "try\n",
    "    mapinator_data = HTTP.get(\"https://support.econjobmarket.org/api/mapinator\", timeout = 120)\n",
    "    placements = JSON.parse(String(mapinator_data.body))\n",
    "catch e\n",
    "    error(\"Failed to retrieve data from the API: $e\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1b\n",
    "Group placements by applicant ID and eliminate \"oid 893\" positions (Ocean and Crow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: are the json fields strictly typed? is there a way to easily compensate if the variable types change?\n",
    "\n",
    "applicant_outcomes = Dict{Any, Vector}()\n",
    "applicant_ids = Set{Any}()\n",
    "num_outcomes_selected = 0\n",
    "\n",
    "for outcome in placements\n",
    "    push!(applicant_ids, outcome[\"aid\"])\n",
    "    if outcome[\"to_oid\"] != 893\n",
    "        push!(get!(applicant_outcomes, outcome[\"aid\"], Vector()), outcome)\n",
    "        num_outcomes_selected += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "if DEBUG_LEVEL > 0\n",
    "    println(\"  \", length(placements), \" total placement outcomes\")\n",
    "    println(\"  -\", length(placements) - num_outcomes_selected, \" outcomes at Ocean and Crow\")\n",
    "    println(\"  \", num_outcomes_selected, \" outcomes not at Ocean and Crow\")\n",
    "    println()\n",
    "    println(\"  \", length(applicant_ids), \" total applicants with placements\")\n",
    "    println(\"  -\", length(applicant_ids) - length(applicant_outcomes), \" total applicants with exclusively outcomes at Ocean and Crow\")\n",
    "    println(\"  \", length(applicant_outcomes), \" applicants with outcomes not at Ocean and Crow\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2a\n",
    "Determine the first placement outcome of each individual that occurred after the individual graduated.\\\n",
    "We need to know what the first outcome is BEFORE we filter on types of outcomes, as otherwise we will get incorrectly-identified \"first-time positions\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2b\n",
    "Remove postdoc outcomes so applicants with postdoc positions aren't automatically removed from the data.\\\n",
    "Postdocs are concurrent so the placements are redundant on top of e.g. concurrently-awarded assistant professor positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postdoc_counter = 0\n",
    "finalized_applicant_outcomes = Dict{Any, Any}()\n",
    "\n",
    "for applicant_id in keys(applicant_outcomes)\n",
    "    for outcome in applicant_outcomes[applicant_id]\n",
    "        # if you wish to display postdocs in the sinks, remove the if statement condition \n",
    "        #   and set Post-Doc to have higher priority than Assistant Professor below\n",
    "        # alternatively, to only include postdocs in the sinks that did not receive professorships,\n",
    "        #   do not alter the below code, and instead conduct a second pass \n",
    "        #   to fill in postdoc outcomes for individuals with no professorships\n",
    "        if outcome[\"position_name\"] != \"Post-Doc\"\n",
    "            if !haskey(finalized_applicant_outcomes, applicant_id)\n",
    "                # just add the outcome if the applicant doesn't have any yet\n",
    "                finalized_applicant_outcomes[applicant_id] = outcome\n",
    "            else\n",
    "                # otherwise, the applicant does have at least one other outcome\n",
    "                if outcome[\"startdate\"] < finalized_applicant_outcomes[applicant_id][\"startdate\"]\n",
    "                    # take the earliest outcome of the two and ignore the other\n",
    "                    finalized_applicant_outcomes[applicant_id] = outcome\n",
    "                elseif outcome[\"startdate\"] == finalized_applicant_outcomes[applicant_id][\"startdate\"]\n",
    "                    # sometimes we may have multiple outcomes that started on the same date - follow priority listing\n",
    "                    if outcome[\"position_name\"] in [\"Assistant Professor\"]\n",
    "                        finalized_applicant_outcomes[applicant_id] = outcome\n",
    "                    elseif outcome[\"position_name\"] in [\"Consultant\"] && !(finalized_applicant_outcomes[applicant_id][\"position_name\"] in [\"Assistant Professor\"])\n",
    "                        finalized_applicant_outcomes[applicant_id] = outcome\n",
    "                    elseif outcome[\"position_name\"] in [\"Other Academic\", \"Other Non-Academic\"] && !(finalized_applicant_outcomes[applicant_id][\"position_name\"] in [\"Assistant Professor\", \"Consultant\"])\n",
    "                        finalized_applicant_outcomes[applicant_id] = outcome\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            postdoc_counter += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "if DEBUG_LEVEL > 0\n",
    "    println(\"  -\", length(applicant_outcomes) - length(finalized_applicant_outcomes), \" total applicants removed due to only being postdocs (\", \n",
    "        postdoc_counter, \" total postdoc placements detected)\")\n",
    "    println(\"  \", length(finalized_applicant_outcomes), \" total applicants ported to finalized collection\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3\n",
    "Eliminate everything except:\n",
    "- Assistant Professor\n",
    "- Consultant\n",
    "- Other Academic\n",
    "- Other Non-Academic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add \"Lecturer\" if adjusting sinks later on\n",
    "valid_labels = Set([\"Assistant Professor\", \"Consultant\", \"Other Academic\", \"Other Non-Academic\"])\n",
    "irrelevant_counter = 0\n",
    "removed_labels = Set()\n",
    "\n",
    "for applicant_id in copy(keys(finalized_applicant_outcomes))\n",
    "    outcome = finalized_applicant_outcomes[applicant_id]\n",
    "    if !(outcome[\"position_name\"] in valid_labels)\n",
    "        push!(removed_labels, outcome[\"position_name\"])\n",
    "        delete!(finalized_applicant_outcomes, applicant_id)\n",
    "        irrelevant_counter += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "if DEBUG_LEVEL > 0\n",
    "    println(\"  -\", irrelevant_counter, \" irrelevant applicants removed from the following classes of positions:\")\n",
    "    println(removed_labels)\n",
    "    println(\"  \", length(finalized_applicant_outcomes), \" applicants remaining after irrelevant-position applicants removed:\")\n",
    "    maintained_labels = Dict{Any, Int}()\n",
    "    for applicant_id in keys(finalized_applicant_outcomes)\n",
    "        outcome = finalized_applicant_outcomes[applicant_id]\n",
    "        position_name = outcome[\"position_name\"]\n",
    "        if haskey(maintained_labels, position_name)\n",
    "            maintained_labels[position_name] += 1\n",
    "        else\n",
    "            maintained_labels[position_name] = 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "println(maintained_labels, \" \", sum(values(maintained_labels)), \" total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4\n",
    "Filter-by-year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_year = Dict{Any, Dict}()\n",
    "removed_year_placed = 0\n",
    "\n",
    "remove_years = [] # [\"2022\", \"2023\", \"2024\", \"2025\", \"2026\"] # remove all 2022+ entries\n",
    "\n",
    "for applicant_id in copy(keys(finalized_applicant_outcomes))\n",
    "    outcome = finalized_applicant_outcomes[applicant_id]\n",
    "    if matches(remove_years, outcome[\"startdate\"])\n",
    "        removed_year_placed += 1\n",
    "        delete!(finalized_applicant_outcomes, applicant_id)\n",
    "    else\n",
    "        push!(get!(sorted_by_year, parse(Int, split(outcome[\"startdate\"], \"-\")[1]), Dict()), applicant_id => outcome)\n",
    "    end\n",
    "end\n",
    "\n",
    "if DEBUG_LEVEL > 0\n",
    "    println(\"  -\", removed_year_placed, \" applicants removed due to placement in 2022/2023/2024\")\n",
    "    println(\"  \", length(finalized_applicant_outcomes), \" applicants remaining after year corrections\")\n",
    "    println()\n",
    "end\n",
    "\n",
    "for key in sort(collect(keys(sorted_by_year)))\n",
    "    println(\"Year \", key, \" has \", length(sorted_by_year[key]), \" placement outcomes\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5\n",
    "Save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_check = sum(length(value) for value in values(sorted_by_year))\n",
    "println(\"Total \" * \"$total_check\" * \" applicants in JSON file (compare to\" * \" $(length(finalized_applicant_outcomes)) \" \n",
    "    * \"applicants in finalized_applicant_outcomes: \" * \"$(length(finalized_applicant_outcomes) == total_check ? \"SUCCESS\" : \"FAIL\")\" * \")\")\n",
    "\n",
    "json_str = JSON.json(sorted_by_year, 4)  \n",
    "open(\"to_from_by_year_mapinator_api.json\", \"w\") do f\n",
    "    write(f, json_str)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the API-loading code. We now have the placements, sorted by year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to run the type allocation code on these placements. This is adapted from [create_new_allocation.ipynb](https://github.com/jbrightuniverse/mapinator/blob/master/estimation/create_new_allocation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"type_allocation_flexible.jl\")\n",
    "included_years = keys(sorted_by_year)\n",
    "# auto-detect year interval; change this to select the years of data to include in the estimation\n",
    "YEAR_INTERVAL = minimum(included_years):maximum(included_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_from_by_year_api = sorted_by_year\n",
    "# alternatively, load an existing file of placement data\n",
    "# to_from_by_year_api = SBM_flexible.fetch_data(\"to_from_by_year.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the placements, we can sort them into academic and sink placements, as well as collect some labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic, academic_to, academic_builder, rough_sink_builder, institution_mapping, reverse_mapping = SBM_flexible.get_builders(to_from_by_year_api, YEAR_INTERVAL);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are mostly flexible in how we choose to design the set of sinks to include. One exception is teaching universities, which must always be included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sink of teaching universities that do not graduate PhDs\n",
    "# this must be constructed using academic placements, not pre-defined sink placements\n",
    "\n",
    "teaching_universities = Set() \n",
    "for dept_name in academic_to\n",
    "    if !(dept_name in academic)\n",
    "        # the department hired an assistant professor but never graduated anyone\n",
    "        push!(teaching_universities, dept_name)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest are built by standardized `if` statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_sector = (\"Public Sector\", Set())\n",
    "private_sector = (\"Private Sector\", Set())\n",
    "other_groups = (\"Other Groups\", Set())\n",
    "\n",
    "postdocs = (\"Postdocs\", Set())\n",
    "lecturers = (\"Lecturers\", Set())\n",
    "other_academic = (\"Other Academic\", Set())\n",
    "\n",
    "for outcome in rough_sink_builder\n",
    "    if outcome[\"recruiter_type\"] == 5 # government institution\n",
    "        push!(public_sector[2], (string(outcome[\"to_name\"], \" ($(public_sector[1]))\"), outcome))\n",
    "    elseif outcome[\"recruiter_type\"] in [6, 7] # private sector: for and not for profit\n",
    "        push!(private_sector[2], (string(outcome[\"to_name\"], \" ($(private_sector[1]))\"), outcome))\n",
    "    elseif outcome[\"recruiter_type\"] == 8 # international organizations, think tanks, assorted\n",
    "        push!(other_groups[2], (string(outcome[\"to_name\"], \" ($(other_groups[1]))\"), outcome))\n",
    "\n",
    "    # some other examples\n",
    "    # every example here must also have a corresponding sink Set() above, \n",
    "    #     and an entry in sinks_to_include below\n",
    "   \n",
    "    elseif outcome[\"postype\"] == 6\n",
    "        # postdocs that are not in the above (i.e. academic; not public, private, or other)\n",
    "        # requires reconfiguration of the to_from_by_year loading code\n",
    "        push!(postdocs[2], (string(outcome[\"to_name\"], \" ($(postdocs[1]))\"), outcome))\n",
    "    elseif outcome[\"postype\"] in [5, 7]\n",
    "        # lecturers that are not in the above\n",
    "        # requires reconfiguration of the to_from_by_year loading code\n",
    "        push!(lecturers[2], (string(outcome[\"to_name\"], \" ($(lecturers[1]))\"), outcome))\n",
    "    else\n",
    "        # everything else including terminal academic positions\n",
    "        # this sink can only be constructed as an \"else\" statement\n",
    "        push!(other_academic[2], (string(outcome[\"to_name\"], \" ($(other_academic[1]))\"), outcome))\n",
    "    \n",
    "    end\n",
    "end\n",
    "\n",
    "# sort to ensure consistent ordering\n",
    "academic_list = sort(collect(academic))\n",
    "teaching_list = sort(collect(teaching_universities))\n",
    "# to be consistent with the original estimation, we only include these additional sinks:\n",
    "sinks_to_include = (public_sector, private_sector, other_groups)#, postdocs, lecturers, other_academic)\n",
    "\n",
    "sink_builder, sinks, sink_labels = SBM_flexible.build_sinks(sinks_to_include, teaching_list)\n",
    "\n",
    "NUMBER_OF_SINKS = length(sink_labels)\n",
    "institutions = vcat(academic_list, sinks...)\n",
    "println(\"$(length(academic_list)) academic departments, $(length(institutions)) total departments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the adjacency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(academic_builder) + length(sink_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = SBM_flexible.get_adjacency(academic_list, institutions, academic_builder, sink_builder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the SBM type allocation itself. We want to determine the optimal number of types along the way, which we adapt from [estimate_number_of_types.jl](https://github.com/jbrightuniverse/mapinator/blob/master/estimation/estimate_number_of_types.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim, Random\n",
    "Random.seed!(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to solve for the optimal number of types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function β(K, likelihoods, λ, numtotal_test, n)\n",
    "    return likelihoods[K] - λ * ((K * numtotal_test) / 2) * n * log(n)\n",
    "end\n",
    "\n",
    "function w(β_vec)\n",
    "    return β_vec ./ sum(β_vec)\n",
    "end\n",
    "\n",
    "function objective_to_minimize(λ_vec, range_K, likelihoods, numsink, n)\n",
    "    λ = λ_vec[1] # just 1-D\n",
    "    w_vec = w([β(K, likelihoods, λ, K + numsink, n) for K in range_K])\n",
    "    return sum(w_vec .* log.(w_vec))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the likelihoods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = Dict{}()\n",
    "range_K = 1:10\n",
    "\n",
    "Threads.@threads for NUMBER_OF_TYPES_TEST in range_K\n",
    "    println(\"Executing K = $NUMBER_OF_TYPES_TEST types on thread $(Threads.threadid())\")\n",
    "    Random.seed!(0) # for reproducibility\n",
    "    numtotal_test = NUMBER_OF_TYPES_TEST + NUMBER_OF_SINKS\n",
    "    \n",
    "    @time est_obj, est_alloc = SBM_flexible.doit(out, length(academic_list), [length(s) for s in sinks], NUMBER_OF_TYPES_TEST, numtotal_test, 500 * (NUMBER_OF_TYPES_TEST-2) + 1000)\n",
    "    _, _, _, full_likelihood = SBM_flexible.get_allocation(est_alloc, out, NUMBER_OF_TYPES_TEST, numtotal_test, institutions)\n",
    "    likelihoods[NUMBER_OF_TYPES_TEST] = full_likelihood\n",
    "    println(\"Completed K = $NUMBER_OF_TYPES_TEST with likelihood $full_likelihood\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply functions to obtain the optimal number of types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = optimize(λ -> objective_to_minimize(λ, range_K, likelihoods, NUMBER_OF_SINKS, length(institutions)), [0.0])\n",
    "println(\"Optimal hyperparameter:\")\n",
    "# TODO: figure out whether there is a potential issue of a non-singleton argmax set (the argmax needs to be the highest lambda in the set)\n",
    "display(Optim.minimizer(res)[1])\n",
    "candidate_types = [β(K, likelihoods, Optim.minimizer(res)[1], K + NUMBER_OF_SINKS, length(institutions)) for K in range_K]\n",
    "println()\n",
    "println(\"penalized likelihoods: \", candidate_types)\n",
    "println(\"maximum value: \", maximum(candidate_types))\n",
    "println(\" optimal number of types which maximizes the penalized likelihood: \", argmax(candidate_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we re-run the type allocation with the optimal number of types to obtain some initial estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_TYPES = argmax(candidate_types)\n",
    "# NUMBER_OF_TYPES = 4 # can also hard-code this\n",
    "numtotal = NUMBER_OF_TYPES + NUMBER_OF_SINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(0) # for reproducibility\n",
    "@time est_obj, est_alloc = SBM_flexible.doit(out, length(academic_list), [length(s) for s in sinks], NUMBER_OF_TYPES, numtotal, 500 * (NUMBER_OF_TYPES-2) + 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placement_rates, counts, sorted_allocation, full_likelihood = SBM_flexible.get_allocation(est_alloc, out, NUMBER_OF_TYPES, numtotal, institutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placement_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placement_rates ./ counts # means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBM_flexible.nice_table(placement_rates, NUMBER_OF_TYPES, NUMBER_OF_SINKS, sink_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the allocation to file, if we want to explore it later, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dictionary = []\n",
    "for (i, alloc) in enumerate(sorted_allocation)\n",
    "    if alloc in 1:NUMBER_OF_TYPES\n",
    "        inst_id = reverse_mapping[institutions[i]]\n",
    "        push!(type_dictionary, Dict(\"name\" => institutions[i], \"institution_id\" => inst_id, \"type\" => alloc))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\".estimates/id_to_type_api.json\", \"w\") do f\n",
    "    write(f, JSON.json(type_dictionary))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the type allocation at the end of the notebook, as it is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the type allocation and placement rates, we can estimate the underlying model parameters. We draw from two sources, the [chi-square](https://github.com/jbrightuniverse/mapinator/blob/master/estimation/estimate_model_two_rounds.jl) and [maximum likelihood](https://github.com/jbrightuniverse/mapinator/blob/master/estimation/estimate_model_ml.jl) variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BlackBoxOptim, Distributions, ForwardDiff, Integrals, Roots, StatsPlots, DelimitedFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for the mathematics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define p_vec as e.g.\n",
    "# [v2/v1 v3/v2 v4/v3 α1 α2 α3 α4 mu1 mu2 mu3 mu4 mus sg1 sg2 sg3 sg4 sgs]\n",
    "\n",
    "# truncated normal: https://juliastats.org/Distributions.jl/stable/truncate/#Distributions.TruncatedNormal\n",
    "# TODO: update to the most recent notation so the package version can be updated\n",
    "\n",
    "function F(x, ρ, μ, σ, K)\n",
    "    return sum([ρ[i] * cdf(TruncatedNormal(μ[i], σ[i], 0, 1), x) for i in 1:K])\n",
    "end\n",
    "\n",
    "function f(x, ρ, μ, σ, K)\n",
    "    return sum([ρ[i] * pdf(TruncatedNormal(μ[i], σ[i], 0, 1), x) for i in 1:K])\n",
    "end\n",
    "\n",
    "function G(Fim1, Fx, αsum)\n",
    "    return (Fim1 - Fx) / αsum\n",
    "end\n",
    "\n",
    "function κ(i, t, v_rel)\n",
    "    return sum([-log(v_rel[j]) for j in t:i-1])\n",
    "end\n",
    "\n",
    "function fi(x, μ, σ)\n",
    "    return pdf(TruncatedNormal(μ, σ, 0, 1), x)\n",
    "end\n",
    "\n",
    "function q(i, t, Fx_vec, x_vec, ρ, μ, σ, α, v_rel, k, K)\n",
    "    # Fx_vec = [F(x0)=1, F(x1), F(x2), F(x3), ..., F(xk-1)]\n",
    "    # x_vec = [x0 = 1, x1, x2, x3, ..., xk = 0]\n",
    "    # x_vec[s] = x_{s-1}, so the limits of integration are and must be offset by 1 below\n",
    "    # TODO: can some integrals be cached as a speed-up? can some integrals be computed in parallel?\n",
    "    return sum([(α[t]/sum(α[1:s])) * solve(IntegralProblem{false}((x, p) -> exp(-(G(Fx_vec[s], F(x, ρ, μ, σ, K), sum(α[1:s])) + κ(s, t, v_rel))) * fi(x, μ[i], σ[i]), x_vec[s+1], x_vec[s]), HCubatureJL())[1] for s in t:k])\n",
    "end\n",
    "\n",
    "function Fx(t, α, v_rel)\n",
    "    return 1 - sum([-log(v_rel[j])*sum(α[1:j]) for j in 1:t])\n",
    "end\n",
    "\n",
    "function Q2(ratio, β)\n",
    "    return β * (1 - exp(-ratio)) / ratio\n",
    "end\n",
    "\n",
    "function pi(t, α)\n",
    "    return α[t] / sum(α[1:t])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use one of two possible estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function chisquare(p_vec, placements, k, K, M)\n",
    "    v_rel = p_vec[1:k-1]\n",
    "    α = 1.0 * p_vec[k:2k-1] / sum(p_vec[k:2k-1]) # change 1.0 to scale number of graduates vs departments\n",
    "    μ = p_vec[2k:2k+K-1]\n",
    "    σ = p_vec[2k+K:2k+2K-1]\n",
    "    ρ = p_vec[2k+2K:2k+3K-1] / sum(p_vec[2k+2K:2k+3K-1])\n",
    "    β = p_vec[end] # set = 1 to hardcode\n",
    "    \n",
    "    Fx_vec = ones(k) # sets F(x0) = 1 by default; Fx_vec = [F(x0)=1, F(x1), F(x2), F(x3), ..., F(xk-1)]\n",
    "    x_vec = ones(k+1) # x_vec = [x0 = 1, x1, x2, x3, ..., xk = 0]\n",
    "    x_vec[k+1] = 0.0\n",
    "    for t in 1:k-1\n",
    "        Fx_vec_candidate = Fx(t, α, v_rel)\n",
    "        if Fx_vec_candidate <= 0.0 # TODO: if this case occurs, can we speed up q()?\n",
    "            Fx_vec[t+1:k] .= 0.0\n",
    "            x_vec[t+1:k] .= 0.0\n",
    "            break\n",
    "        end\n",
    "        Fx_vec[t+1] = Fx_vec_candidate\n",
    "        # there is no simple closed-form for F^{-1}(x) so this numerically computes x1, x2, x3\n",
    "        x_vec[t+1] = find_zero(x -> F(x, ρ, μ, σ, K) - Fx_vec[t+1], 0.5) \n",
    "    end\n",
    "    \n",
    "    objective = 0.0\n",
    "    normalizer = 0.0\n",
    "    \n",
    "    q_it = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = q(i, t, Fx_vec, x_vec, ρ, μ, σ, α, v_rel, k, K)\n",
    "        q_it[i, t] = prob\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "    \n",
    "    D = sum([ρ[i] * (1 - sum([q_it[i, t] for t in 1:k])) for i in 1:K])\n",
    "    S = sum([α[t] * (1 - sum([ρ[i]*q_it[i, t] for i in 1:K])) for t in 1:k])\n",
    "    round_2 = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = (1 - sum([q_it[i, s] for s in 1:k])) * Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "        round_2[i, t] = prob\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "    \n",
    "    # TODO: div by zero and negative floating point edge cases in mean\n",
    "    for i in 1:K, t in 1:k \n",
    "        expectation = M * (ρ[i] * (q_it[i, t] + round_2[i, t]) / normalizer)\n",
    "        objective += (placements[i, t] - expectation) ^ 2 / expectation\n",
    "    end\n",
    "\n",
    "    return objective\n",
    "end\n",
    "\n",
    "function print_metrics_chisquare(p_vec, placements, k, K, M)\n",
    "    v_rel = p_vec[1:k-1]\n",
    "    α = 1.0 * p_vec[k:2k-1] / sum(p_vec[k:2k-1]) # change 1.0 to scale number of graduates vs departments\n",
    "    μ = p_vec[2k:2k+K-1]\n",
    "    σ = p_vec[2k+K:2k+2K-1]\n",
    "    ρ = p_vec[2k+2K:2k+3K-1] / sum(p_vec[2k+2K:2k+3K-1])\n",
    "    β = p_vec[end] # set = 1 to hardcode\n",
    "\n",
    "    Fx_vec = ones(k)\n",
    "    x_vec = ones(k+1)\n",
    "    x_vec[k+1] = 0.0\n",
    "    for t in 1:k-1\n",
    "        Fx_vec_candidate = Fx(t, α, v_rel)\n",
    "        if Fx_vec_candidate <= 0.0\n",
    "            Fx_vec[t+1:k] .= 0.0\n",
    "            x_vec[t+1:k] .= 0.0\n",
    "            break\n",
    "        end\n",
    "        Fx_vec[t+1] = Fx_vec_candidate\n",
    "        x_vec[t+1] = find_zero(x -> F(x, ρ, μ, σ, K) - Fx_vec[t+1], 0.5) \n",
    "    end\n",
    "\n",
    "    objective = 0.0\n",
    "    normalizer = 0.0\n",
    "    \n",
    "    q_it = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = q(i, t, Fx_vec, x_vec, ρ, μ, σ, α, v_rel, k, K)\n",
    "        q_it[i, t] = prob\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "    \n",
    "    D = sum([ρ[i] * (1 - sum([q_it[i, t] for t in 1:k])) for i in 1:K])\n",
    "    S = sum([α[t] * (1 - sum([ρ[i]*q_it[i, t] for i in 1:K])) for t in 1:k])\n",
    "    round_2 = zeros(K, k)\n",
    "    round_2_hiring = zeros(K, k)\n",
    "\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = (1 - sum([q_it[i, s] for s in 1:k])) * Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "        round_2[i, t] = prob\n",
    "        round_2_hiring[i, t] = Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "\n",
    "    round_1_failure = zeros(K)\n",
    "    for i in 1:K\n",
    "        round_1_failure[i] = (1 - sum([q_it[i, s] for s in 1:k]))\n",
    "    end\n",
    "    \n",
    "    # TODO: div by zero and negative floating point in mean\n",
    "    exp_placements_round_1 = zeros(K, k)\n",
    "    exp_placements_round_2 = zeros(K, k)\n",
    "    exp_placements = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k \n",
    "        expectation = M * (ρ[i] * (q_it[i, t] + round_2[i, t]) / normalizer)\n",
    "        exp_placements_round_1[i, t] = M * (ρ[i] * q_it[i, t] / normalizer)\n",
    "        exp_placements_round_2[i, t] = M * (ρ[i] * round_2[i, t] / normalizer)\n",
    "        exp_placements[i, t] = expectation\n",
    "        objective += (placements[i, t] - expectation) ^ 2 / expectation\n",
    "    end\n",
    "\n",
    "    println(\"objective value = \", objective)\n",
    "    println(\"success sample size (departments) = \", M)\n",
    "    println(\"estimated total samples (departments) = \", M / normalizer)\n",
    "    println(\"estimated unmatched departments = \", (M / normalizer) - M)\n",
    "    println(\"probability of any success: \", normalizer)\n",
    "    println(\"probability of no success: \", 1 - normalizer)\n",
    "    println(\"measure of departments in round 2 = \", D)\n",
    "    println(\"measure of graduates in round 2 = \", S)\n",
    "    println()\n",
    "    println(\"predicted fraction of departments of each tier:\")\n",
    "    display(ρ)\n",
    "    println()\n",
    "    println(\"fractions observed among successful departments in data:\")\n",
    "    display(sum(placements, dims = 2) ./ M)\n",
    "    println()\n",
    "\n",
    "    for i in 1:k\n",
    "        println(\"pi_\", i, \" = \", pi(i, α))\n",
    "    end\n",
    "    println()\n",
    "\n",
    "    offer_targets = zeros(k, k)\n",
    "    for t in 1:k, j in 1:t\n",
    "        offer_targets[t, j] = pi(j, α) * prod([1 - pi(i, α) for i in j+1:t])\n",
    "    end\n",
    "    println(\"Tier selection probabilities for making offers:\")\n",
    "    display(offer_targets)\n",
    "    println()\n",
    "\n",
    "    println(\"Round 1 hiring probabilities:\")\n",
    "    display(q_it)\n",
    "    println()\n",
    "\n",
    "    println(\"Probabilities of failing round 1\")\n",
    "    display(round_1_failure)\n",
    "    println()\n",
    "\n",
    "    println(\"Probabilities of failing round 1 and hiring in round 2:\")\n",
    "    display(round_2)\n",
    "    println()\n",
    "\n",
    "    println(\"Round 2 hiring probabilities:\")\n",
    "    display(round_2_hiring)\n",
    "    println()\n",
    "\n",
    "    for i in 1:k+1\n",
    "        println(\"x_\", i - 1, \" = \", x_vec[i])\n",
    "    end\n",
    "    println()\n",
    "    for i in 1:k\n",
    "        println(\"F(x_\", i - 1, \") = \", Fx_vec[i])\n",
    "    end\n",
    "    println()\n",
    "    for i in 1:k\n",
    "        println(\"α_\", i, \" = \", α[i])\n",
    "        println(\"  Est. graduates: \", α[i] * (M / normalizer - 1))\n",
    "        println(\"  Successful: \", sum(placements[:, i]))\n",
    "        println(\"  Unsuccessful: \", (α[i] * (M / normalizer - 1)) - sum(placements[:, i]))\n",
    "    end\n",
    "    println(\"Total estimated graduates: \", sum(α) * (M / normalizer - 1))\n",
    "    println(\"Total successful graduates: \", M)\n",
    "    println(\"Total estimated unsuccessful graduates: \", (sum(α) * (M / normalizer - 1)) - M)\n",
    "    println(\"β = \", β)\n",
    "    println()\n",
    "    println(\"estimated placement rates, round 1 only:\")\n",
    "    display(exp_placements_round_1)\n",
    "    println()\n",
    "    println(\"estimated placement rates, round 2 only:\")\n",
    "    display(exp_placements_round_2)\n",
    "    println()\n",
    "    println(\"estimated placement rates, cumulative:\")\n",
    "    display(exp_placements)\n",
    "    println()\n",
    "    println(\"actual placement rates:\")\n",
    "    display(placements)\n",
    "    println()\n",
    "    println(\"difference between estimated and actual placement rates:\")\n",
    "    display(exp_placements - placements)\n",
    "    println()\n",
    "    println(\"chi-square p-value\")\n",
    "    println(1 - cdf(Chisq((size(placements)[1] - 1) * (size(placements)[2] - 1)), objective))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function estimate_likelihood(p_vec, placements, k, K, M)\n",
    "    v_rel = p_vec[1:k-1]\n",
    "    α = 1.0 * p_vec[k:2k-1] / sum(p_vec[k:2k-1]) # change 1.0 to scale number of graduates vs departments\n",
    "    μ = p_vec[2k:2k+K-1]\n",
    "    σ = p_vec[2k+K:2k+2K-1]\n",
    "    ρ = p_vec[2k+2K:2k+3K-1] / sum(p_vec[2k+2K:2k+3K-1])\n",
    "    β = p_vec[end] # set = 1 to hardcode\n",
    "    \n",
    "    Fx_vec = ones(k) # sets F(x0) = 1 by default; Fx_vec = [F(x0)=1, F(x1), F(x2), F(x3), ..., F(xk-1)]\n",
    "    x_vec = ones(k+1) # x_vec = [x0 = 1, x1, x2, x3, ..., xk = 0]\n",
    "    x_vec[k+1] = 0.0\n",
    "    for t in 1:k-1\n",
    "        Fx_vec_candidate = Fx(t, α, v_rel)\n",
    "        if Fx_vec_candidate <= 0.0 # TODO: if this case occurs, can we speed up q()?\n",
    "            Fx_vec[t+1:k] .= 0.0\n",
    "            x_vec[t+1:k] .= 0.0\n",
    "            break\n",
    "        end\n",
    "        Fx_vec[t+1] = Fx_vec_candidate\n",
    "        # there is no simple closed-form for F^{-1}(x) so this numerically computes x1, x2, x3\n",
    "        x_vec[t+1] = find_zero(x -> F(x, ρ, μ, σ, K) - Fx_vec[t+1], 0.5) \n",
    "    end\n",
    "\n",
    "    objective = 0.0\n",
    "    normalizer = 0.0\n",
    "\n",
    "    q_it = zeros(K, k)\n",
    "    for i in 1:K\n",
    "        for t in 1:k\n",
    "            prob = q(i, t, Fx_vec, x_vec, ρ, μ, σ, α, v_rel, k, K)\n",
    "            q_it[i, t] = prob\n",
    "            normalizer += ρ[i] * prob\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # TODO: div by zero and negative floating point in mean\n",
    "    D = sum([ρ[i] * (1 - sum([q_it[i, t] for t in 1:k])) for i in 1:K])\n",
    "    S = sum([α[t] * (1 - sum([ρ[i]*q_it[i, t] for i in 1:K])) for t in 1:k])\n",
    "    for i in 1:K\n",
    "        for t in 1:k\n",
    "            prob = (1 - sum([q_it[i, s] for s in 1:k])) * Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "            # println(sum([q_it[i, s] for s in 1:k]))\n",
    "            # println(t, \" \", i, \" \", ρ[i] * (q_it[i, t] + prob), \" \", ρ[i], \" \", q_it[i, t], \" \", (1 - sum([q_it[i, s] for s in 1:k])), \" \", Q2(D/S, β), \" \", α[t], \" \", (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])), \" \", S, \" \", prob)\n",
    "            objective += placements[i, t] * (log(ρ[i] * (q_it[i, t] + prob)))\n",
    "            normalizer += ρ[i] * prob\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    objective -= M * log(normalizer)\n",
    "    return -objective\n",
    "end\n",
    "\n",
    "function print_metrics_maximum_likelihood(p_vec, placements, k, K, M)\n",
    "    v_rel = p_vec[1:k-1]\n",
    "    α = 1.0 * p_vec[k:2k-1] / sum(p_vec[k:2k-1]) # change 1.0 to scale number of graduates vs departments\n",
    "    μ = p_vec[2k:2k+K-1]\n",
    "    σ = p_vec[2k+K:2k+2K-1]\n",
    "    ρ = p_vec[2k+2K:2k+3K-1] / sum(p_vec[2k+2K:2k+3K-1])\n",
    "    β = p_vec[end] # set = 1 to hardcode\n",
    "\n",
    "    Fx_vec = ones(k)\n",
    "    x_vec = ones(k+1)\n",
    "    x_vec[k+1] = 0.0\n",
    "    for t in 1:k-1\n",
    "        Fx_vec_candidate = Fx(t, α, v_rel)\n",
    "        if Fx_vec_candidate <= 0.0\n",
    "            Fx_vec[t+1:k] .= 0.0\n",
    "            x_vec[t+1:k] .= 0.0\n",
    "            break\n",
    "        end\n",
    "        Fx_vec[t+1] = Fx_vec_candidate\n",
    "        x_vec[t+1] = find_zero(x -> F(x, ρ, μ, σ, K) - Fx_vec[t+1], 0.5) \n",
    "    end\n",
    "\n",
    "    objective = 0.0\n",
    "    likelihood = 0.0\n",
    "    normalizer = 0.0\n",
    "    \n",
    "    q_it = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = q(i, t, Fx_vec, x_vec, ρ, μ, σ, α, v_rel, k, K)\n",
    "        q_it[i, t] = prob\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "    \n",
    "    # TODO: div by zero and negative floating point in mean\n",
    "    D = sum([ρ[i] * (1 - sum([q_it[i, t] for t in 1:k])) for i in 1:K])\n",
    "    S = sum([α[t] * (1 - sum([ρ[i]*q_it[i, t] for i in 1:K])) for t in 1:k])\n",
    "    round_2 = zeros(K, k)\n",
    "    round_2_hiring = zeros(K, k)\n",
    "\n",
    "    for i in 1:K, t in 1:k\n",
    "        prob = (1 - sum([q_it[i, s] for s in 1:k])) * Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "        round_2[i, t] = prob\n",
    "        round_2_hiring[i, t] = Q2(D/S, β) * α[t] * (1 - sum([ρ[j] * q_it[j, t] for j in 1:K])) / S\n",
    "        normalizer += ρ[i] * prob\n",
    "    end\n",
    "\n",
    "    round_1_failure = zeros(K)\n",
    "    for i in 1:K\n",
    "        round_1_failure[i] = (1 - sum([q_it[i, s] for s in 1:k]))\n",
    "    end\n",
    "    \n",
    "    exp_placements_round_1 = zeros(K, k)\n",
    "    exp_placements_round_2 = zeros(K, k)\n",
    "    exp_placements = zeros(K, k)\n",
    "    for i in 1:K, t in 1:k \n",
    "        expectation = M * (ρ[i] * (q_it[i, t] + round_2[i, t]) / normalizer)\n",
    "        exp_placements_round_1[i, t] = M * (ρ[i] * q_it[i, t] / normalizer)\n",
    "        exp_placements_round_2[i, t] = M * (ρ[i] * round_2[i, t] / normalizer)\n",
    "        exp_placements[i, t] = expectation\n",
    "        objective += (placements[i, t] - expectation) ^ 2 / expectation\n",
    "        likelihood += placements[i, t] * (log(ρ[i] * (q_it[i, t] + round_2[i, t])))\n",
    "        likelihood -= log(factorial(big(placements[i, t])))\n",
    "    end\n",
    "    likelihood -= M * log(normalizer)\n",
    "\n",
    "    println(\"chi-square objective value = \", objective)\n",
    "    println(\"log-likelihood objective value = \", likelihood)\n",
    "    println(\"likelihood objective value = \", exp(likelihood))\n",
    "    println(\"success sample size (departments) = \", M)\n",
    "    println(\"estimated total samples (departments) = \", M / normalizer)\n",
    "    println(\"estimated unmatched departments = \", (M / normalizer) - M)\n",
    "    println(\"probability of any success: \", normalizer)\n",
    "    println(\"probability of no success: \", 1 - normalizer)\n",
    "    println(\"measure of departments in round 2 = \", D)\n",
    "    println(\"measure of graduates in round 2 = \", S)\n",
    "    println()\n",
    "    println(\"predicted fraction of departments of each tier:\")\n",
    "    display(ρ)\n",
    "    println()\n",
    "    println(\"fractions observed among successful departments in data:\")\n",
    "    display(sum(placements, dims = 2) ./ M)\n",
    "    println()\n",
    "\n",
    "    for i in 1:k\n",
    "        println(\"pi_\", i, \" = \", pi(i, α))\n",
    "    end\n",
    "    println()\n",
    "\n",
    "    offer_targets = zeros(k, k)\n",
    "    for t in 1:k, j in 1:t\n",
    "        offer_targets[t, j] = pi(j, α) * prod([1 - pi(i, α) for i in j+1:t])\n",
    "    end\n",
    "    println(\"Tier selection probabilities for making offers:\")\n",
    "    display(offer_targets)\n",
    "    println()\n",
    "\n",
    "    println(\"Round 1 hiring probabilities:\")\n",
    "    display(q_it)\n",
    "    println()\n",
    "\n",
    "    println(\"Probabilities of failing round 1\")\n",
    "    display(round_1_failure)\n",
    "    println()\n",
    "\n",
    "    println(\"Probabilities of failing round 1 and hiring in round 2:\")\n",
    "    display(round_2)\n",
    "    println()\n",
    "\n",
    "    println(\"Round 2 hiring probabilities:\")\n",
    "    display(round_2_hiring)\n",
    "    println()\n",
    "\n",
    "    for i in 1:k+1\n",
    "        println(\"x_\", i - 1, \" = \", x_vec[i])\n",
    "    end\n",
    "    println()\n",
    "    for i in 1:k\n",
    "        println(\"F(x_\", i - 1, \") = \", Fx_vec[i])\n",
    "    end\n",
    "    println()\n",
    "    for i in 1:k\n",
    "        println(\"α_\", i, \" = \", α[i])\n",
    "        println(\"  Est. graduates: \", α[i] * (M / normalizer - 1))\n",
    "        println(\"  Successful: \", sum(placements[:, i]))\n",
    "        println(\"  Unsuccessful: \", (α[i] * (M / normalizer - 1)) - sum(placements[:, i]))\n",
    "    end\n",
    "    println(\"Total estimated graduates: \", sum(α) * (M / normalizer - 1))\n",
    "    println(\"Total successful graduates: \", M)\n",
    "    println(\"Total estimated unsuccessful graduates: \", (sum(α) * (M / normalizer - 1)) - M)\n",
    "    println(\"β = \", β)\n",
    "    println()\n",
    "    println(\"estimated placement rates, round 1 only:\")\n",
    "    display(exp_placements_round_1)\n",
    "    println()\n",
    "    println(\"estimated placement rates, round 2 only:\")\n",
    "    display(exp_placements_round_2)\n",
    "    println()\n",
    "    println(\"estimated placement rates, cumulative:\")\n",
    "    display(exp_placements)\n",
    "    println()\n",
    "    println(\"actual placement rates:\")\n",
    "    display(placements)\n",
    "    println()\n",
    "    println(\"difference between estimated and actual placement rates:\")\n",
    "    display(exp_placements - placements)\n",
    "    println()\n",
    "    println(\"chi-square p-value\")\n",
    "    println(1 - cdf(Chisq((size(placements)[1] - 1) * (size(placements)[2] - 1)), objective))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use our earlier results to produce the estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(0) # for reproducibility\n",
    "res = (;placements = placement_rates)\n",
    "# res = (;placements = [496 66 33 3; 455 196 84 12; 725 618 363 43; 84 148 83 63; 126 66 41 29; 359 258 131 34; 447 206 94 18; 394 523 508 143]) # can also load an adjacency matrix directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = NUMBER_OF_TYPES\n",
    "K = numtotal\n",
    "M = sum(res.placements)\n",
    "\n",
    "# upper bound on the value ratios, which should all be less than 1\n",
    "# if any ratio turns out to be 1.0 or close to it at optimality, this could indicate that a lower tier has a higher value than a higher one\n",
    "upper = [1.0 for _ in 1:k-1] \n",
    "\n",
    "# upper bound on variables proportionate to alpha\n",
    "append!(upper, [1.0 for _ in 1:k])\n",
    "\n",
    "# upper bound on the mu parameter of truncated normal, which is strictly within [0, 1] as the mean is greater than mu in truncated normal\n",
    "append!(upper, [1.0 for _ in 1:K])\n",
    "\n",
    "# upper bound on the sigma parameter of truncated normal\n",
    "append!(upper, [5.0 for _ in 1:K])\n",
    "\n",
    "# upper bound on variables proportionate to rho\n",
    "append!(upper, [1.0 for _ in 1:K])\n",
    "\n",
    "# upper bound on beta friction parameter\n",
    "push!(upper, 1.0)\n",
    "\n",
    "# all lower bounds are zero as these should be positive parameters\n",
    "# can swap estimate_likelihood for chi_square\n",
    "sol_res = bboptimize(p -> estimate_likelihood(p, res.placements, k, K, M), SearchRange = [(0.0, upper[i]) for i in eachindex(upper)], MaxFuncEvals = 100000, TraceInterval = 5)\n",
    "sol = best_candidate(sol_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the correct metrics function is used based on the selected optimizer\n",
    "print_metrics_maximum_likelihood(sol, res.placements, k, K, M)\n",
    "\n",
    "for i in 1:k-1\n",
    "    println(\"v_\", i + 1, \"/v_\", i, \" = \", sol[i])\n",
    "end\n",
    "\n",
    "v_base = 1\n",
    "for i in 1:k\n",
    "    println(\"v\", i, \": \", v_base)\n",
    "    if i != k\n",
    "        v_base = sol[i] * v_base\n",
    "    end\n",
    "end\n",
    "\n",
    "for select_type in 1:k\n",
    "    println(\"mean for type \", select_type, \": \", mean(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1)))\n",
    "    println(\"stddev for type \", select_type, \": \", std(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1)))\n",
    "    println()\n",
    "end\n",
    "for select_type in k+1:K\n",
    "    println(\"mean for sink \", select_type - k, \": \", mean(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1)))\n",
    "    println(\"stddev for sink \", select_type - k, \": \", std(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1)))\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the CDFs and PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/JuliaPlots/StatsPlots.jl/blob/master/README.md\n",
    "# https://docs.juliaplots.org/latest/tutorial/\n",
    "\n",
    "select_type = 1\n",
    "cdfs = plot(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = cdf, title = \"CDFs of Types\", label = \"Type 1\")\n",
    "for select_type in 2:NUMBER_OF_TYPES # academic types\n",
    "    plot!(cdfs, TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = cdf, label = string(\"Type \", select_type))\n",
    "end\n",
    "\n",
    "for select_type in k+1:K # sinks\n",
    "    plot!(cdfs, TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = cdf, label = string(\"Sink \", select_type - k))\n",
    "end\n",
    "xlabel!(cdfs, \"offer value\")\n",
    "ylabel!(cdfs, \"F(offer value)\")\n",
    "savefig(cdfs, \"cdfs.png\")\n",
    "cdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_type = 1\n",
    "pdfs = plot(TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = pdf, title = \"PDFs of Types\", label = \"Type 1\")\n",
    "for select_type in 2:k # academic types\n",
    "    plot!(pdfs, TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = pdf, label = string(\"Type \", select_type))\n",
    "end\n",
    "\n",
    "for select_type in k+1:K # sinks\n",
    "    plot!(pdfs, TruncatedNormal(sol[2k-1+select_type], sol[2k-1+select_type+K], 0, 1), func = pdf, label = string(\"Sink \", select_type - k))\n",
    "end\n",
    "xlabel!(pdfs, \"offer value\")\n",
    "ylabel!(pdfs, \"f(offer value)\")\n",
    "savefig(pdfs, \"pdfs.png\")\n",
    "pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the coarse-grained type allocation from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sorted_type in 1:NUMBER_OF_TYPES+NUMBER_OF_SINKS\n",
    "    counter = 0\n",
    "    inst_hold = []\n",
    "    println(\"TYPE $sorted_type:\")\n",
    "    for (i, sbm_type) in enumerate(sorted_allocation)\n",
    "        if sbm_type == sorted_type\n",
    "            push!(inst_hold, institutions[i])\n",
    "            counter += 1\n",
    "        end\n",
    "    end\n",
    "    for inst in sort(inst_hold)\n",
    "        println(\"  \", inst)\n",
    "    end\n",
    "    println(\"Total Institutions: $counter\")\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing we can do is to estimate a fine-grained department ranking using the estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ones(k)\n",
    "v_base = 1\n",
    "for i in 1:k-1\n",
    "    v_base = sol[i] * v_base\n",
    "    values[i+1] = v_base\n",
    "end\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rank departments by the total expected value of their graduates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valued_indices = []\n",
    "for i in 1:size(out)[2]\n",
    "    total_graduate_value = values[sorted_allocation[i]] * sum(out[:, i])\n",
    "    push!(valued_indices, (institutions[i], total_graduate_value))\n",
    "end\n",
    "sort!(valued_indices, by = x -> x[2], rev = true)\n",
    "for (j, entry) in enumerate(valued_indices)\n",
    "    println(\"$(j). $(entry[1]) ($(entry[2]))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by the total expected value of their hires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valued_indices_hire = []\n",
    "for i in 1:size(out)[2]\n",
    "    total_hire_value = 0\n",
    "    for j in 1:size(out)[2]\n",
    "        total_hire_value += values[sorted_allocation[j]] * out[i, j]\n",
    "    end\n",
    "    push!(valued_indices_hire, (institutions[i], total_hire_value))\n",
    "end\n",
    "sort!(valued_indices_hire, by = x -> x[2], rev = true)\n",
    "for (j, entry) in enumerate(valued_indices_hire)\n",
    "    println(\"$(j). $(entry[1]) ($(entry[2]))\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (6 threads) 1.8.5",
   "language": "julia",
   "name": "julia-(6-threads)-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
